// The Swift Programming Language
// https://docs.swift.org/swift-book
@preconcurrency import Vision
import UIKit // Precisamos importar UIKit para usar UIImage

// MARK: -  Classificador de Pets
public struct Classification {
    public let label: String
    public let confidence: Float
    public var confidencePercentage: String {
        return String(format: "%.1f%%", confidence * 100)
    }
}

/// Define os tipos de erros que podem ocorrer durante a classifica√ß√£o.
public enum ClassifierError: Error {
    case modelLoadingFailed(Error), imageProcessingFailed(Error), classificationFailed
}

// MARK: - Classificador Principal

/// A classe principal para interagir com o modelo de classifica√ß√£o de pets.
public class PetClassifier {
    // O modelo de Core ML √© carregado uma √∫nica vez e compartilhado por todas as chamadas.
    private static let sharedModel: VNCoreMLModel = {
        do {
            let configuracao = MLModelConfiguration()
            let modelo = try PetDetector(configuration: configuracao).model
            return try VNCoreMLModel(for: modelo)
        } catch {
            fatalError("Falha cr√≠tica ao carregar o modelo de Core ML: \(error)")
        }
    }()
    
    /// Analisa uma imagem para determinar se ela cont√©m um pet. √â a √∫nica fun√ß√£o que voc√™ precisa chamar.
    /// Exemplo de uso: `let isPet = await PetClassifier.analyze(image: suaImagem)`
    public static func analyze(image: UIImage?) async -> String {
        // Valida e converte a UIImage para CGImage em um √∫nico passo.
        guard let cgImage = image?.cgImage else {
            print("Nenhuma imagem v√°lida fornecida para an√°lise.")
            return ""
        }
        
        // Converte a l√≥gica de completion handler do Vision para o moderno async/await.
        return await withCheckedContinuation { continuation in
            // Cria e configura a requisi√ß√£o de an√°lise.
            let request = VNCoreMLRequest(model: sharedModel) { request, error in
                // Ap√≥s a an√°lise, verifica os resultados.
                guard let results = request.results as? [VNClassificationObservation],
                      let bestResult = results.first, error == nil else {
                    print("üö® Erro ou nenhum resultado retornado pela an√°lise: \(error?.localizedDescription ?? "N/A")")
                    continuation.resume(returning: "")
                    return
                }
                
                // Processa o melhor resultado.
                let isPet = bestResult.identifier
                print(isPet)
                
                // Cria uma inst√¢ncia da nossa struct para usar a formata√ß√£o da porcentagem.
                let classification = Classification(label: bestResult.identifier, confidence: bestResult.confidence)

//                print("\n---------------------------------")
//                print("Resultado da An√°lise do Pacote:")
//                print("   - \(isPet ? "√â um Pet!" : "N√£o √© um Pet.")")
//                print("   - Label Detectada: '\(classification.label)'")
//                print("   - Confian√ßa: \(classification.confidencePercentage)")
//                print("---------------------------------")
                continuation.resume(returning: isPet)
            }
            request.imageCropAndScaleOption = .centerCrop
            
            // Executa a requisi√ß√£o.
            do {
                try VNImageRequestHandler(cgImage: cgImage).perform([request])
            } catch {
                print("Falha ao executar a requisi√ß√£o do Vision: \(error.localizedDescription)")
                continuation.resume(returning: "")
            }
        }
    }
}
